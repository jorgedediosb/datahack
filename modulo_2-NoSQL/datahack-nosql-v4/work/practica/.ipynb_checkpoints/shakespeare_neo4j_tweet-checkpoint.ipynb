{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Shakespeare / Twitter Graph\n",
    "\n",
    "En este ejercicio vamos a modelar la obra de Shakespeare como si fuese red social de Twitter en Neo4j.\n",
    "\n",
    "* Un 'personaje' 'dice' unas 'líneas de texto', por lo tanto es su 'autor'.\n",
    "* Las 'líneas de  texto' contienen un 'texto' y este 'texto' puede tener 'lugares'.\n",
    "* Un 'personaje' puede 'mencionar' a otro 'personaje' en una 'línea de texto'.\n",
    "* Un 'personaje' puede 'repetir' una 'línea de texto' de otro 'personaje' en una nueva 'línea de texto'.\n",
    "\n",
    "El dataset usado tiene el siguiente formato:\n",
    "\n",
    "`\n",
    "{\n",
    "    \"type\": \"String\", --> (act, scene or line)\n",
    "    \"line_id\": INT,\n",
    "    \"play_name\": \"String\",\n",
    "    \"speech_number\": INT,\n",
    "    \"line_number\": \"String\",\n",
    "    \"speaker\": \"String\",\n",
    "    \"text_entry\": \"String\"\n",
    "}\n",
    "`\n",
    "\n",
    "El grafo que queremos generar (basado en twitter) es el siguiente:\n",
    "\n",
    "![png](../images/neo4j/shakespeare_twitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de empezar con el ejercico, vamos a importar las librerías necesarias para trabajar sobre Neo4j.\n",
    "\n",
    "Como hacemos siempre, borramos todos los nodos y relaciones que existen en la base de datos para partir de un entorno limpio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprintpp import pprint as pp\n",
    "from py2neo import Graph, Relationship, Node\n",
    "import json\n",
    "\n",
    "graph = Graph(\"http://neo4j:1234@neo4j:7474/db/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"MATCH (n) DETACH DELETE n\").evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar ídices y constraints\n",
    "graph.run(\"\"\"\n",
    "CALL db.indexes()\n",
    "\"\"\").to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propiedad 'line_id' de los nodos etiquetados como 'TEXT' debe ser única:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"CREATE CONSTRAINT ON (text:Text) ASSERT text.line_id IS UNIQUE\").evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propiedad 'name' de los nodos etiquetados como 'Chararter' debe ser única:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"CREATE CONSTRAINT ON (chararter:Chararter) ASSERT chararter.name IS UNIQUE\").evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La propiedad 'place' de los nodos etiquetados como 'Place' debe ser única:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"CREATE CONSTRAINT ON (place:Place) ASSERT place.place IS UNIQUE\").evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de realizar las búsquedas, vamos a insertar unos cuantos datos en el grafo con la estructura que hemos definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBA!!\n",
    "# El dataset del 'TEXT' está en formato JSON y crea un nodo con los datos de ese 'personaje'.\n",
    "# Como resultado devuelve el nodo creado.\n",
    "def parse_chararter(chararter_json):\n",
    "    \n",
    "    # Crea el nodo con la etiqueta \"Chararter\" y le asigna el valor a la propiedad \"name\" que es única.\n",
    "    # 'speaker' es la propiedad dentro de cada documento json del dataset\n",
    "    chararter = Node(\"Chararter\", name = chararter_json['speaker'])\n",
    "    \n",
    "    # Para el resto de propiedades del personaje, si el dato existe en el JSON lo añade al nodo con el metodo update()\n",
    "    if 'play_name' in chararter_json:\n",
    "        chararter.update(play_name = chararter_json['play_name'])\n",
    "    if 'speech_number' in chararter_json:\n",
    "        chararter.update(speech_number = chararter_json['speech_number'])\n",
    "    if 'line_number' in chararter_json:\n",
    "        chararter.update(line_number = chararter_json['line_number'])\n",
    "    if 'text_entry' in chararter_json:\n",
    "        chararter.update(text_entry = chararter_json['text_entry'])\n",
    "    \n",
    "    try:\n",
    "        # Crea el nodo 'chararter' en neo4j\n",
    "        graph.create(chararter)\n",
    "    except:\n",
    "        # Si existe lanza una excepción ya que el nombre de personaje debe ser único en la  obra (¿lo será?).\n",
    "        # Buscamos el nodo que ya existe por nombe de personaje y lo devolvemos.\n",
    "        # Utilizamos el método run que permite ejecutar cualquier sentencia.\n",
    "        chararter = graph.run(\"MATCH (chararter:Chararter {name : '%s'}) RETURN chararter\" % (chararter_json['speaker'])).evaluate()\n",
    "        pass\n",
    "\n",
    "    # Devolvemos el nodo creado\n",
    "    return chararter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsea cada documento del dataset y crea tanto el Nodo TEXT, como el Nodo CHARARTER que crea el testo más los nodos CHARARTER de sus menciones\n",
    "#Además crea lo nodos 'PLACE' con los lugares que contiene el texto.\n",
    "#Por último crea todas las relacciones entre los nodos creados, SAY, MENTION, REPEATED y HAS\n",
    "def parse_text(text_json):\n",
    "    \n",
    "    #Cogemos el campo 'chararter' del json y lo pasamos al método anterior que parsea e inserta el personaje.\n",
    "    chararter = parse_chararter(text_json['speaker'])\n",
    "    \n",
    "    #Creamos el Nodo con el label 'Text' que contien los datos del texto que estamos parseando\n",
    "    text = Node(\"Text\",\n",
    "                 id = text_json['line_id'],\n",
    "                 type = text_json['type'],\n",
    "                 play_name = text_json['play_name'],\n",
    "                 speech_number = text_json['speech_number'],\n",
    "                 line_number = text_json['line_number'],\n",
    "                 text_entry = text_json['text_entry']\n",
    "                )\n",
    "    \n",
    "    try:\n",
    "        # Crea el nodo 'TEXT' en neo4j\n",
    "        graph.create(text)\n",
    "    except:\n",
    "        # Si el texto ya existe lanza una excepción, por lo que lo buscamos y lo asignamos a la variable 'text'.\n",
    "        text = graph.run(\"MATCH (t:Text {id : %s}) RETURN t\" % (text_json['line_id'])).evaluate()\n",
    "        pass\n",
    "    \n",
    "    # Creamos la relacción SAY entre el Nodo de tipo 'Chararter' y el Nodo de tipo 'Text' que hemos insertado\n",
    "    chararter_say_text = Relationship(chararter, \"SAY\", text)\n",
    "    graph.create(chararter_say_text)\n",
    "    \n",
    "    # Comprobamos si tiene menciones y añadimos los nodos de tipo Chararter con los datos del personaje mencionado\n",
    "    # Creamos la relacción MENTION entre el texto y el personaje mencionado.\n",
    "    if 'chararter_mention' in text_json:\n",
    "        for chararter_mention_json in text_json['chararter_mention']:\n",
    "            chararter_mentioned = parse_chararter(chararter_mention_json)\n",
    "            text_mentioned_chararter = Relationship(text, \"MENTION\", chararter_mencioned)\n",
    "            graph.create(text_mentioned_)\n",
    " \n",
    "    # Comprobamos si el texto contiene lugares y si es así creamos los nodos de tipo 'PLACE' y las relacciones 'HAS' ente el lugar y el texto que lo contiene.\n",
    "    if 'text_entry' in text_json:\n",
    "        for place in text_json['text_entry']:\n",
    "            place = Node(\"Place\", place = text_entry)\n",
    "            try:\n",
    "                graph.create(place)\n",
    "            except:\n",
    "                place = graph.run(\"MATCH (p:Place {place : '%s'}) RETURN p\" % (text_entry)).evaluate()\n",
    "                pass\n",
    "            text_Place_place = Relationship(text, \"HAS\", place)\n",
    "            graph.create(text_Place_place)\n",
    "\n",
    "    # Por último comprobamos si se trata de un texto repetido y si es así creamos la relacción REPEATED entre el \n",
    "    # texto y el personaje que lo ha repetido\n",
    "    if 'repeated_status' in text_json:\n",
    "        chararter_repeated = parse_chararter(text_json['repeated_status']['chararter'])\n",
    "        text_repeaterOf_chararter = Relationship(text, \"REPEATED\", chararter_repeated)\n",
    "        graph.create(tweet_retweetOf_user)\n",
    "        \n",
    "        parse_text(text_json['repeated_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este método lee el fichero indicado por parámetro. \n",
    "# Parsea cada linea en formato JSON. Cada línea representa un texto.\n",
    "def load_file(text_data_path):\n",
    "    text_file = open(text_data_path, \"r\")\n",
    "    for text in text_file:\n",
    "        parse_text(json.loads(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga el fichero con los textos.\n",
    "load_file('../data/neo4j/data_shakespeare.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
